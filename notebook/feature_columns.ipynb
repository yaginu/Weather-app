{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680a63eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_path = \"##########\"\n",
    "validation_file_path = \"##########\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c2d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "# Setting defaults\n",
    "CSV_COLUMNS = [\n",
    "    'day_sin', 'day_cos', 'year_sin', 'year_cos', 'air_pressure_ashore', 'air_pressure_afloat',\n",
    "    'diff_air_pressure', 'precipitation', 'is_rainny', 'temperature', 'humidity', 'wind_vector_x', \"wind_vector_y\",\n",
    "    'hours_of_daylight', 'global_solar_radiation', 'weather', 'cloud_cover', 'temp_mean', 'temp_var'\n",
    "]\n",
    "\n",
    "SELECT_COLUMNS = [\n",
    "    'day_sin', 'day_cos', 'year_sin', 'year_cos', 'air_pressure_ashore', 'air_pressure_afloat',\n",
    "    'diff_air_pressure', 'precipitation', 'is_rainny', 'temperature', 'humidity', 'wind_vector_x', \"wind_vector_y\",\n",
    "    'hours_of_daylight', 'global_solar_radiation', 'weather', 'cloud_cover'\n",
    "]    \n",
    "\n",
    "DEFAULTS = [[0.0] for _ in range(len(SELECT_COLUMNS))]\n",
    "\n",
    "# Loading dataset\n",
    "def load_dataset(filename, batch_size, mode):\n",
    "    \n",
    "    # Packing features\n",
    "    def pack(features):\n",
    "        packed_features =  tf.stack(list(features.values()), axis=1)\n",
    "\n",
    "        return tf.reshape(packed_features, [-1])\n",
    "    \n",
    "    @tf.function\n",
    "    def marshal(x, feature_keys):\n",
    "        features = {\n",
    "            k: x[:, feature_keys.index(k)] for k in feature_keys\n",
    "        }\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def cast_to_integer(x, int_features):\n",
    "        features = {\n",
    "            k: tf.cast(v, tf.int64) if k in int_features else v for k, v in x.items()\n",
    "        }\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def zero_zip(input):\n",
    "        return {\"encoder_inputs\": input, \"decoder_inputs\": {\"start_inputs\" : tf.zeros(shape=(1,))}}\n",
    "\n",
    "    # Window processing\n",
    "    def windowed_dataset(dataset, batch_size, mode):\n",
    "        CATEGORICAL_FEATURES = [\"is_rainny\", \"weather\", \"cloud_cover\"]\n",
    "        \n",
    "        marshal_fn_partial = partial(marshal, feature_keys=SELECT_COLUMNS)\n",
    "        cast_to_integer_fn_partial = partial(cast_to_integer, int_features=CATEGORICAL_FEATURES)\n",
    "        \n",
    "        dataset = dataset.map(pack)\n",
    "        dataset = dataset.window(size=48, shift=1, drop_remainder=True)\n",
    "        dataset = dataset.flat_map(lambda window: window.batch(48))\n",
    "\n",
    "        if mode == \"train\":\n",
    "            dataset.shuffle(1000)\n",
    "        \n",
    "        if mode == \"train\" or mode == \"eval\":    \n",
    "            encoder_input = dataset.map(lambda window: window[:24]).map(marshal_fn_partial).map(cast_to_integer_fn_partial)\n",
    "            decoder_input = dataset.map(lambda window: tf.concat((tf.zeros((1)), window[24:-1, 9]), axis=0))\n",
    "            decoder_output = dataset.map(lambda window: window[24:, 9])\n",
    "\n",
    "            inputs = tf.data.Dataset.zip((encoder_input, decoder_input))\n",
    "            dataset = tf.data.Dataset.zip((inputs, decoder_output)).cache()\n",
    "            \n",
    "        else:\n",
    "            x_test = dataset.map(lambda window: window[:24]).map(marshal_fn_partial)\n",
    "            y_true = dataset.map(lambda window: window[24:, 9])\n",
    "                        \n",
    "            x_test = x_test.map(zero_zip)\n",
    "            \n",
    "            dataset = tf.data.Dataset.zip((x_test, y_true)).cache()\n",
    "            \n",
    "        dataset = dataset.batch(batch_size, drop_remainder=True).repeat(1).prefetch(1)  \n",
    "        \n",
    "        return dataset\n",
    "    \n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "            file_pattern=filename,\n",
    "            column_names=CSV_COLUMNS,\n",
    "            column_defaults=DEFAULTS,\n",
    "            select_columns=SELECT_COLUMNS,\n",
    "            batch_size=1,\n",
    "            shuffle=False,\n",
    "            num_epochs=1)\n",
    "\n",
    "    dataset = windowed_dataset(dataset, batch_size, mode)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e02f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(training_file_path, 256, \"train\")\n",
    "valid_dataset = load_dataset(validation_file_path, 128, \"eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebf1e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_FEATURES = [\"is_rainny\", \"weather\", \"cloud_cover\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c8ce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sparse_tensor(dense):\n",
    "\n",
    "    # sequence_numeric_column default is float32\n",
    "    zero = tf.constant(-100.0, dtype=tf.dtypes.float32) \n",
    "\n",
    "    where = tf.not_equal(dense, zero)\n",
    "    indices = tf.where(where)\n",
    "    values = tf.gather_nd(dense, indices)\n",
    "\n",
    "    return tf.SparseTensor(indices, values, tf.shape(dense, out_type=tf.dtypes.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dbfc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORM_ARTEFACTS_DIR = \"##########\"\n",
    "tf_transform_output = tft.TFTransformOutput(TRANSFORM_ARTEFACTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3a26d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_feature_columns = []\n",
    "\n",
    "for feature_name in SELECT_COLUMNS:\n",
    "    if feature_name in CATEGORICAL_FEATURES:\n",
    "        NUM_BUCKETS = tf_transform_output.vocabulary_size_by_name(feature_name)\n",
    "        categorical_features = tf.feature_column.sequence_categorical_column_with_identity(feature_name, num_buckets=NUM_BUCKETS)\n",
    "        categorical_features_one_hot = tf.feature_column.indicator_column(categorical_features)\n",
    "        sequence_feature_columns.append(categorical_features_one_hot)\n",
    "        \n",
    "    else:\n",
    "        numerical_features = tf.feature_column.sequence_numeric_column(feature_name, normalizer_fn=to_sparse_tensor)\n",
    "        sequence_feature_columns.append(numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a747019",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT_COLUMNS = [\n",
    "    'day_sin', 'day_cos', 'year_sin', 'year_cos', 'air_pressure_ashore', 'air_pressure_afloat',\n",
    "    'diff_air_pressure', 'precipitation', 'is_rainny', 'temperature', 'humidity', 'wind_vector_x', \"wind_vector_y\",\n",
    "    'hours_of_daylight', 'global_solar_radiation', 'weather', 'cloud_cover'\n",
    "]\n",
    "\n",
    "encoder_input_layers = {\n",
    "    colname: tf.keras.layers.Input(name=colname, shape=(24, 1), dtype=tf.int64)\n",
    "    if colname in CATEGORICAL_FEATURES else tf.keras.layers.Input(name=colname, shape=(24, 1), dtype=tf.float32) for colname in SELECT_COLUMNS\n",
    "}\n",
    "\n",
    "sequence_input, sequence_length = tf.keras.experimental.SequenceFeatures(sequence_feature_columns)(encoder_input_layers)\n",
    "\n",
    "# Encoder\n",
    "encoder_lstm = tf.keras.layers.LSTM(256, return_sequences=True, name=\"encoder_lstm1\")(sequence_input)\n",
    "encoder_dropout = tf.keras.layers.Dropout(0.2, name=\"encoder_dropout\")(encoder_lstm)\n",
    "encoder_output, state_h, state_c = tf.keras.layers.LSTM(256, return_state=True, name=\"encoder_lstm2\")(encoder_dropout)\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "# Sampler\n",
    "sampler = tfa.seq2seq.sampler.ScheduledOutputTrainingSampler(\n",
    "    sampling_probability=0.,\n",
    "    next_inputs_fn=lambda outputs: tf.reshape(outputs, shape=(1, 1))\n",
    ")\n",
    "sampler.sampling_probability = tf.Variable(0.)\n",
    "\n",
    "# Decoder\n",
    "decoder_input = tf.keras.layers.Input(shape=(24, 1), name=\"decoder_input\")\n",
    "\n",
    "decoder_cell = tf.keras.layers.LSTMCell(256, name=\"decoder_lstm\")\n",
    "output_layer = tf.keras.layers.Dense(1, name=\"decoder_output\")\n",
    "\n",
    "decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell, sampler, output_layer=output_layer)\n",
    "\n",
    "decoder_output, _, _ = decoder(decoder_input, initial_state=encoder_state, sequence_length=[24])\n",
    "\n",
    "final_output = decoder_output.rnn_output\n",
    "\n",
    "# Creating model\n",
    "model = tf.keras.Model(inputs=[encoder_input_layers, decoder_input], outputs=[final_output])\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4fa4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ace95e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset, epochs=1, validation_data=valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed90697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference sampler\n",
    "inference_sampler = tfa.seq2seq.sampler.InferenceSampler(\n",
    "    sample_fn = lambda outputs: outputs,\n",
    "    sample_shape = [1],\n",
    "    sample_dtype = tf.float32,\n",
    "    end_fn = lambda sample_ids : False\n",
    ")\n",
    "\n",
    "# Inference decoder\n",
    "inference_decoder = tfa.seq2seq.basic_decoder.BasicDecoder(\n",
    "    decoder_cell, inference_sampler, output_layer=output_layer, maximum_iterations=24\n",
    ")\n",
    "\n",
    "start_inputs = tf.keras.layers.Input(shape=(1), name=\"start_inputs\", dtype=tf.float32)\n",
    "\n",
    "decoder_output, _, _ = inference_decoder(start_inputs, initial_state=encoder_state)\n",
    "\n",
    "final_output = decoder_output.rnn_output\n",
    "\n",
    "# Creating inference model\n",
    "inference_model = tf.keras.Model(\n",
    "    inputs={\"encoder_inputs\": encoder_input_layers, \"decoder_inputs\": {\"start_inputs\": start_inputs}},\n",
    "    outputs=[final_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40e68a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(inference_model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9310f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT_COLUMNS = [\n",
    "    'day_sin', 'day_cos', 'year_sin', 'year_cos', 'air_pressure_ashore', 'air_pressure_afloat',\n",
    "    'diff_air_pressure', 'precipitation', 'is_rainny', 'temperature', 'humidity', 'wind_vector_x', \"wind_vector_y\",\n",
    "    'hours_of_daylight', 'global_solar_radiation', 'weather', 'cloud_cover'\n",
    "]\n",
    "\n",
    "encoder_input_layers = {\n",
    "    colname: tf.keras.layers.Input(name=colname, shape=(24, 1), dtype=tf.int64)\n",
    "    if colname in CATEGORICAL_FEATURES else tf.keras.layers.Input(name=colname, shape=(24, 1), dtype=tf.float32) for colname in SELECT_COLUMNS\n",
    "}\n",
    "\n",
    "sequence_input, sequence_length = tf.keras.experimental.SequenceFeatures(sequence_feature_columns)(encoder_input_layers)\n",
    "\n",
    "# Encoder\n",
    "encoder_lstm = tf.keras.layers.LSTM(256, return_sequences=True, name=\"encoder_lstm1\")(sequence_input)\n",
    "encoder_dropout = tf.keras.layers.Dropout(0.2, name=\"encoder_dropout\")(encoder_lstm)\n",
    "encoder_output, state_h, state_c = tf.keras.layers.LSTM(256, return_state=True, return_sequences=True, name=\"encoder_lstm2\")(encoder_dropout)\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "# Sampler\n",
    "sampler = tfa.seq2seq.sampler.ScheduledOutputTrainingSampler(\n",
    "    sampling_probability=0.,\n",
    "    next_inputs_fn=lambda outputs: tf.reshape(outputs, shape=(1, 1))\n",
    ")\n",
    "sampler.sampling_probability = tf.Variable(0.)\n",
    "\n",
    "# Decoder\n",
    "decoder_input = tf.keras.layers.Input(shape=[24, 1], name=\"decoder_input\")\n",
    "\n",
    "attention_mechanism = tfa.seq2seq.LuongAttention(256, encoder_output)\n",
    "\n",
    "decoder_cell = tf.keras.layers.LSTMCell(256, name=\"decoder_lstm\")\n",
    "decoder_cell = tfa.seq2seq.AttentionWrapper(\n",
    "    decoder_cell,\n",
    "    attention_mechanism\n",
    ")\n",
    "\n",
    "output_layer = tf.keras.layers.Dense(1, name=\"decoder_output\")\n",
    "\n",
    "decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell, sampler, output_layer=output_layer)\n",
    "\n",
    "decoder_initial_state = decoder_cell.get_initial_state(dtype=tf.float32, batch_size=tf.shape(decoder_input)[0])\n",
    "decoder_initial_state = decoder_initial_state.clone(cell_state=encoder_state)\n",
    "\n",
    "decoder_output, _, _ = decoder(decoder_input, initial_state=decoder_initial_state, sequence_length=[24])\n",
    "\n",
    "final_output = decoder_output.rnn_output\n",
    "\n",
    "# Creating model\n",
    "model = tf.keras.Model(inputs=[encoder_input_layers, decoder_input], outputs=[final_output])\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c791dfd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m73",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m73"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
